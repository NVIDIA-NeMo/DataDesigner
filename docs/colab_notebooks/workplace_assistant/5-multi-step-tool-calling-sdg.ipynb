{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building Multi-Step Tool-Calling Datasets with Data Designer\n",
        "\n",
        "Generate synthetic training data for agentic Reinforcement-Learning using NVIDIA **Data Designer** and **NeMo Gym** to enhance multi-step tool calling ability.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- **NVIDIA API Key** from [build.nvidia.com](https://build.nvidia.com) to access a remote LLM for generation. Alternatively, you may choose to use your own endpoint or deployment.\n",
        "- **Python 3.11+**\n",
        "- **Tool definition files** in the `tools/` directory (included in this repo)\n",
        "- Packages: `data-designer`, `pydantic`, `pandas`\n",
        "\n",
        "## Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "\n",
        "- Load known **tool schemas** as the seed for generating agent queries and simulated trajectories\n",
        "- Use **Data Designer** to generate realistic multi-step user queries\n",
        "- Simulate **agent trajectories** (step-by-step tool-call solutions)\n",
        "- Apply **dual-level LLM judge filtering** to ensure data quality\n",
        "- Export training data in **NeMo Gym format** for rollout collection and RLVR training\n",
        "\n",
        "# \n",
        "#\n",
        "> **Context Note:** The primary goal of this notebook is user query generation. The trajectory generation step in this notebook serves as a sanity check to ensure the generated query leads to a feasible path. In production RL training, rollout (oracle trajectory) traces are generated from the environment itself. You may find more information in [NeMo Gym Rollout Collection](https://docs.nvidia.com/nemo/gym/latest/get-started/rollout-collection.html) documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Architecture Overview\n",
        "\n",
        "```\n",
        " ┌───────────────────────────────────────────────────────────────┐\n",
        " │                  DATA GENERATION PIPELINE                     │\n",
        " ├───────────────────────────────────────────────────────────────┤\n",
        " │                                                               │\n",
        " │   ┌──────────────┐    ┌──────────────┐    ┌──────────────┐    │\n",
        " │   │ Tool Schemas │───▶│  User Query  │───▶│  Trajectory  │    │\n",
        " │   │    (Seed)    │    │ Generation   │    │ Simulation   │    │\n",
        " │   └──────────────┘    └──────────────┘    └──────────────┘    │\n",
        " │                                                  │            │\n",
        " │                                                  ▼            │\n",
        " │                                           ┌──────────────┐    │\n",
        " │                                           │  LLM Judge   │    │\n",
        " │                                           │  (Quality)   │    │\n",
        " │                                           └──────────────┘    │\n",
        " │                                                  │            │\n",
        " │                                                  ▼            │\n",
        " │                                           ┌──────────────┐    │\n",
        " │                                           │  NeMo Gym    │    │\n",
        " │                                           │   Format     │    │\n",
        " │                                           └──────────────┘    │\n",
        " │                                                               │\n",
        " └───────────────────────────────────────────────────────────────┘\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q data-designer pydantic pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "import pandas as pd\n",
        "\n",
        "# Data Designer imports\n",
        "from data_designer.essentials import (\n",
        "    ChatCompletionInferenceParams,\n",
        "    DataDesigner,\n",
        "    DataDesignerConfigBuilder,\n",
        "    LLMStructuredColumnConfig,\n",
        "    LLMTextColumnConfig,\n",
        "    LocalFileSeedSource,\n",
        "    ModelConfig,\n",
        "    SamplingStrategy,\n",
        "    ModelProvider\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Context: What is the Workplace Assistant Environment?\n",
        "\n",
        "[**Workplace Assistant**](https://docs.nvidia.com/nemo/gym/latest/tutorials/nemo-rl-grpo/about-workplace-assistant.html#) is a multi-step tool-using benchmark environment used in **NeMo Gym** for RL training. A model gets a natural language business request and must call tools in the right order with valid arguments (up to 6 steps).\n",
        "\n",
        "At a high level:\n",
        "- The model reads a user request (for example, scheduling meetings or updating CRM records)\n",
        "- The model decides which tools to call and with what parameters\n",
        "- The environment verifies correctness using **state matching** (final database state), not exact step matching\n",
        "\n",
        "In this notebook, we focus on **data generation**: starting from known tool schemas, generating realistic user requests, and simulating feasible trajectories to produce NeMo Gym-compatible training data.\n",
        "\n",
        "> **Note:** The official NeMo Gym [Workplace Assistant environment](https://github.com/NVIDIA-NeMo/Gym/tree/main/resources_servers/workplace_assistant) is the training target. This notebook is an example synthetic data preparation stage that feeds that workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Tool Definitions\n",
        "\n",
        "This notebook begins with **established tool schemas** and leverages them as foundational context for data generation. These schemas represent the (possibly domain-specific) tools on which you aim to enhance model performance.\n",
        "\n",
        "We use 27 tools across 6 tool groups:\n",
        "- **Company Directory**: Look up employee email addresses\n",
        "- **Email**: Send, search, reply, forward, delete emails\n",
        "- **Calendar**: Create, search, update, delete events\n",
        "- **Analytics**: Query website visitor data and create plots\n",
        "- **Project Management**: Manage tasks across Kanban boards\n",
        "- **CRM**: Manage customer records and sales pipeline\n",
        "\n",
        "These tools are designed to require **multi-step reasoning**. For example:\n",
        "- \"Email John about the meeting\" requires first looking up John's email, then sending\n",
        "- \"Reassign all of Sarah's leads to Mike\" requires looking up emails, searching customers, then updating each one\n",
        "\n",
        "> **Why this matters:** The schemas define valid arguments and values (for example, allowed board/list/status values). We use these constraints to generate realistic user queries and schema-compliant simulated trajectories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 27 tools across 6 databases\n",
            "\n",
            "Databases:\n",
            "  - company_directory: 1 tools\n",
            "    Employee directory for looking up email addresses by name.\n",
            "  - email: 6 tools\n",
            "    Email inbox and outbox for sending, receiving, and managing emails.\n",
            "  - calendar: 5 tools\n",
            "    Calendar for managing meetings and events.\n",
            "  - analytics: 6 tools\n",
            "    Website analytics data for tracking visitor behavior and engagement.\n",
            "  - project_management: 5 tools\n",
            "    Project management board for tracking tasks across teams.\n",
            "  - customer_relationship_manager: 4 tools\n",
            "    CRM for managing customer records and sales pipeline.\n"
          ]
        }
      ],
      "source": [
        "# Load tool definitions from separate JSON files (one per database)\n",
        "import os\n",
        "\n",
        "TOOLS_DIR = 'tools'\n",
        "\n",
        "# Load environment config\n",
        "with open(os.path.join(TOOLS_DIR, 'environment.json'), 'r') as f:\n",
        "    env_config = json.load(f)\n",
        "\n",
        "SYSTEM_PROMPT = env_config['system_prompt']\n",
        "MULTI_STEP_PATTERNS = env_config['common_multi_step_patterns']\n",
        "\n",
        "# Load tools from each database file\n",
        "DATABASE_FILES = [\n",
        "    'company_directory.json',\n",
        "    'email.json', \n",
        "    'calendar.json',\n",
        "    'analytics.json',\n",
        "    'project_management.json',\n",
        "    'customer_relationship_manager.json'\n",
        "]\n",
        "\n",
        "TOOLS = []\n",
        "DATABASES = {}\n",
        "TOOL_CATEGORIES = {}\n",
        "\n",
        "for db_file in DATABASE_FILES:\n",
        "    with open(os.path.join(TOOLS_DIR, db_file), 'r') as f:\n",
        "        db_config = json.load(f)\n",
        "        \n",
        "    db_name = db_config['database']\n",
        "    DATABASES[db_name] = {\n",
        "        'description': db_config['description'],\n",
        "        'data_schema': db_config['data_schema']\n",
        "    }\n",
        "    \n",
        "    # Add tools and track category\n",
        "    db_tools = db_config['tools']\n",
        "    TOOLS.extend(db_tools)\n",
        "    TOOL_CATEGORIES[db_name] = [t['name'] for t in db_tools]\n",
        "\n",
        "print(f\"Loaded {len(TOOLS)} tools across {len(DATABASES)} databases\")\n",
        "print(f\"\\nDatabases:\")\n",
        "for db_name, db_info in DATABASES.items():\n",
        "    tool_count = len(TOOL_CATEGORIES[db_name])\n",
        "    print(f\"  - {db_name}: {tool_count} tools\")\n",
        "    print(f\"    {db_info['description']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display all loaded tools grouped by database. This summary shows each tool's name and description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### COMPANY_DIRECTORY (1 tools)\n",
            "- **company_directory_find_email_address**: Finds all email addresses containing the given name (case-insensitive search).\n",
            "\n",
            "### EMAIL (6 tools)\n",
            "- **email_get_email_information_by_id**: Retrieves specific details of an email by its ID.\n",
            "- **email_search_emails**: Searches for emails matching the given query across subject, body, or sender fields. The function matches an email if all words in the query appear in any of these fields.\n",
            "- **email_send_email**: Sends an email to the specified recipient.\n",
            "- **email_delete_email**: Deletes an email by its ID.\n",
            "- **email_forward_email**: Forwards an email to the specified recipient.\n",
            "- **email_reply_email**: Replies to an email by its ID.\n",
            "\n",
            "### CALENDAR (5 tools)\n",
            "- **calendar_get_event_information_by_id**: Returns the event for a given ID.\n",
            "- **calendar_search_events**: Returns the events for a given query with pagination support.\n",
            "- **calendar_create_event**: Creates a new event.\n",
            "- **calendar_delete_event**: Deletes an event.\n",
            "- **calendar_update_event**: Updates an event.\n",
            "\n",
            "### ANALYTICS (6 tools)\n",
            "- **analytics_get_visitor_information_by_id**: Returns the analytics data for a given visitor ID.\n",
            "- **analytics_create_plot**: Plots the analytics data for a given time range and value.\n",
            "- **analytics_total_visits_count**: Returns the total number of visits within a specified time range.\n",
            "- **analytics_engaged_users_count**: Returns the number of engaged users within a specified time range.\n",
            "- **analytics_traffic_source_count**: Returns the number of visits from a specific traffic source within a specified time range.\n",
            "- **analytics_get_average_session_duration**: Returns the average session duration within a specified time range.\n",
            "\n",
            "### PROJECT_MANAGEMENT (5 tools)\n",
            "- **project_management_get_task_information_by_id**: Returns the task information for a given ID.\n",
            "- **project_management_search_tasks**: Searches for tasks based on the given parameters.\n",
            "- **project_management_create_task**: Creates a new task.\n",
            "- **project_management_delete_task**: Deletes a task by ID.\n",
            "- **project_management_update_task**: Updates a task by ID.\n",
            "\n",
            "### CUSTOMER_RELATIONSHIP_MANAGER (4 tools)\n",
            "- **customer_relationship_manager_search_customers**: Searches for customers based on the given parameters with pagination support.\n",
            "- **customer_relationship_manager_update_customer**: Updates a customer record by ID.\n",
            "- **customer_relationship_manager_add_customer**: Adds a new customer record.\n",
            "- **customer_relationship_manager_delete_customer**: Deletes a customer record by ID.\n"
          ]
        }
      ],
      "source": [
        "# Helper function to format tools for prompts\n",
        "def format_tools_for_prompt(tools: List[dict], include_schemas: bool = False) -> str:\n",
        "    \"\"\"Format tool definitions into a readable string for LLM prompts.\"\"\"\n",
        "    lines = []\n",
        "    for tool in tools:\n",
        "        lines.append(f\"- **{tool['name']}**: {tool['description']}\")\n",
        "        if include_schemas:\n",
        "            params = tool['parameters']['properties']\n",
        "            if params:\n",
        "                lines.append(f\"  Parameters: {list(params.keys())}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Display tool summary by category\n",
        "for category, tool_names in TOOL_CATEGORIES.items():\n",
        "    print(f\"\\n### {category.upper()} ({len(tool_names)} tools)\")\n",
        "    category_tools = [t for t in TOOLS if t['name'] in tool_names]\n",
        "    print(format_tools_for_prompt(category_tools))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define Output Schemas\n",
        "\n",
        "**Data Designer** uses **Pydantic** models to define structured output formats, ensuring the LLM generates data in a consistent, parseable format.\n",
        "\n",
        "We define five schemas:\n",
        "1. **ToolCall** / **AgentStep** / **AgentTrajectory**: Represent a multi-step tool-calling solution\n",
        "2. **UserQueryJudgeScores**: Quality scores for generated user queries\n",
        "3. **TrajectoryJudgeScores**: Quality scores for generated trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ToolCall(BaseModel):\n",
        "    \"\"\"A single tool invocation.\"\"\"\n",
        "    name: str = Field(..., description=\"The name of the tool to call (e.g., 'email_send_email')\")\n",
        "    arguments: str = Field(..., description=\"JSON string of the tool arguments\")\n",
        "\n",
        "\n",
        "class AgentStep(BaseModel):\n",
        "    \"\"\"A single step in the agent's reasoning trajectory.\"\"\"\n",
        "    step_number: int = Field(..., description=\"The step number (1-indexed)\")\n",
        "    thought: str = Field(\n",
        "        ..., \n",
        "        description=\"The agent's reasoning about what to do next and why. Should explain the purpose of the tool call.\"\n",
        "    )\n",
        "    tool_call: ToolCall = Field(..., description=\"The tool to call in this step\")\n",
        "    expected_result: str = Field(\n",
        "        ..., \n",
        "        description=\"What information or state change we expect from this tool call\"\n",
        "    )\n",
        "\n",
        "\n",
        "class AgentTrajectory(BaseModel):\n",
        "    \"\"\"Complete trajectory for solving a multi-step task.\"\"\"\n",
        "    reasoning_trace: List[AgentStep] = Field(\n",
        "        ..., \n",
        "        description=\"The sequence of steps to solve the task. Should be 1-6 steps.\"\n",
        "    )\n",
        "    final_answer: str = Field(\n",
        "        ..., \n",
        "        description=\"A brief confirmation of what was accomplished\"\n",
        "    )\n",
        "\n",
        "\n",
        "class UserQueryJudgeScores(BaseModel):\n",
        "    \"\"\"Quality scores for the generated user query.\"\"\"\n",
        "    feasibility: int = Field(\n",
        "        ..., ge=1, le=5, \n",
        "        description=\"Is the request achievable with the available tools? (1=impossible, 5=fully achievable)\"\n",
        "    )\n",
        "    schema_compliance: int = Field(\n",
        "        ..., ge=1, le=5, \n",
        "        description=\"Does the request use valid values as defined in tool schemas (e.g., valid board names, list names, statuses)? (1=uses invalid values, 5=all values valid)\"\n",
        "    )\n",
        "    naturalness: int = Field(\n",
        "        ..., ge=1, le=5, \n",
        "        description=\"Does the request sound like a natural user query? (1=robotic/artificial, 5=very natural)\"\n",
        "    )\n",
        "    is_valid: bool = Field(\n",
        "        ..., \n",
        "        description=\"True if the query is valid and should be kept, False if it should be discarded\"\n",
        "    )\n",
        "    issues: str = Field(\n",
        "        ..., \n",
        "        description=\"List any issues found (invalid enum values, impossible requests, etc.) or 'None' if valid\"\n",
        "    )\n",
        "\n",
        "\n",
        "class TrajectoryJudgeScores(BaseModel):\n",
        "    \"\"\"Quality scores for the generated trajectory.\"\"\"\n",
        "    tool_validity: int = Field(\n",
        "        ..., ge=1, le=5, \n",
        "        description=\"Are all tool names valid and arguments schema-compliant? (1=invalid tools/args, 5=all valid)\"\n",
        "    )\n",
        "    argument_validity: int = Field(\n",
        "        ..., ge=1, le=5, \n",
        "        description=\"Do all arguments use valid values as specified in tool descriptions? (1=invalid values, 5=all valid)\"\n",
        "    )\n",
        "    completeness: int = Field(\n",
        "        ..., ge=1, le=5, \n",
        "        description=\"Does the trajectory fully solve the user request? (1=incomplete, 5=fully complete)\"\n",
        "    )\n",
        "    efficiency: int = Field(\n",
        "        ..., ge=1, le=5, \n",
        "        description=\"Is the trajectory optimal without unnecessary steps? (1=very inefficient, 5=optimal)\"\n",
        "    )\n",
        "    is_valid: bool = Field(\n",
        "        ..., \n",
        "        description=\"True if the trajectory is valid and executable, False if it has errors\"\n",
        "    )\n",
        "    issues: str = Field(\n",
        "        ..., \n",
        "        description=\"List any issues found (invalid enum values, wrong tool names, missing steps, etc.) or 'None' if valid\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Define Generation Prompts\n",
        "\n",
        "The heart of synthetic data generation is the prompts. We define four prompts using **Jinja2 templates** (with `{{ variable }}` placeholders that Data Designer fills from seed columns):\n",
        "\n",
        "1. **User Query Generation**: Create realistic workplace requests\n",
        "2. **Trajectory Simulation**: Generate the step-by-step tool-call solution\n",
        "3. **User Query Judge**: Evaluate query feasibility and schema compliance\n",
        "4. **Trajectory Judge**: Evaluate tool-call correctness and completeness\n",
        "\n",
        "### Key Principles\n",
        "- **Specificity**: Tell the LLM exactly what format you want\n",
        "- **Examples**: Show don't tell — include concrete examples by complexity level\n",
        "- **Constraints**: Define what NOT to do (avoid trivial tasks, don't skip steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Query Generation Prompt loaded\n"
          ]
        }
      ],
      "source": [
        "# Prompt 1: Generate a realistic user query that may require one or more tool calls\n",
        "USER_QUERY_GENERATION_PROMPT = \"\"\"\n",
        "You are creating training data for a workplace assistant AI agent.\n",
        "\n",
        "**Your Task:** Generate a realistic user request that requires the agent to use one or more tools to complete.\n",
        "\n",
        "**Available Tools (with full schemas):**\n",
        "{{ tools_json }}\n",
        "\n",
        "**Selected Tool Category:** {{ category }}\n",
        "\n",
        "**Multi-Step Pattern to Use:** {{ pattern }}\n",
        "\n",
        "**CRITICAL - Valid Values:**\n",
        "Many tool parameters have RESTRICTED VALUES specified in their descriptions. You MUST only reference values that exist in the tool schemas. Pay close attention to phrases like \"One of:\" in parameter descriptions.\n",
        "\n",
        "Common restrictions to follow:\n",
        "- `list_name`: Only use 'Backlog', 'In Progress', 'In Review', or 'Completed' (NOT 'Prospects', 'Todo', 'Pipeline', etc.)\n",
        "- `board`: Only use 'Back end', 'Front end', or 'Design' (NOT 'Sales', 'Marketing', 'Engineering', etc.)\n",
        "- `status`: Only use 'Qualified', 'Won', 'Lost', 'Lead', or 'Proposal' (NOT 'Active', 'Prospect', 'Closed', etc.)\n",
        "- `product_interest`: Only use 'Software', 'Hardware', 'Services', 'Consulting', or 'Training'\n",
        "\n",
        "**Guidelines:**\n",
        "1. The request should sound natural - like something a real employee would ask\n",
        "2. It should require 1-6 tool calls to complete\n",
        "3. Include specific details that make the task concrete (names, dates, subjects)\n",
        "4. Don't mention tool names or technical details - speak like a normal user\n",
        "5. The task MUST be achievable with the available tools using ONLY valid parameter values\n",
        "6. When referencing boards, lists, statuses, etc., use EXACTLY the values allowed in the tool schemas\n",
        "\n",
        "**Examples by Complexity:**\n",
        "\n",
        "*Simple (1 step):*\n",
        "- \"Reply to Carlos's last email about the prototype with 'Thanks, I'll review it tomorrow'\"\n",
        "- \"Change the name of my 3pm meeting to 'Risk Management Forum'\"\n",
        "- \"How many website visitors did we have last week?\"\n",
        "\n",
        "*Medium (2-3 steps):*\n",
        "- \"Send an email to John about the quarterly review meeting tomorrow\"\n",
        "- \"Schedule a 30-minute sync with Lisa tomorrow at 2pm\"\n",
        "- \"Get the total visits and engaged users for November\"\n",
        "\n",
        "*Complex (4-6 steps):*\n",
        "- \"Raj is taking over all of Akira's leads that are interested in software. Can you reassign them in the CRM?\"\n",
        "- \"Forward the last email from marketing about the Q4 report to everyone on the design team\"\n",
        "- \"Move all of Sarah's overdue tasks on the Back end board to the Backlog\"\n",
        "\n",
        "**Output:** Return ONLY the user request as a single string. No quotes, no explanation.\n",
        "\"\"\"\n",
        "\n",
        "print(\"User Query Generation Prompt loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trajectory Simulation Prompt loaded\n"
          ]
        }
      ],
      "source": [
        "# Prompt 2: Simulate the agent's trajectory for solving the task\n",
        "TRAJECTORY_SIMULATION_PROMPT = \"\"\"\n",
        "You are simulating an expert workplace assistant agent solving a task step-by-step.\n",
        "\n",
        "**User Request:**\n",
        "{{ user_query }}\n",
        "\n",
        "**System Context:**\n",
        "{{ system_prompt }}\n",
        "\n",
        "**Available Tools:**\n",
        "{{ tools_json }}\n",
        "\n",
        "**Your Task:** Generate a step-by-step trajectory showing how the agent would solve this request.\n",
        "\n",
        "**Guidelines:**\n",
        "1. **Think Step-by-Step**: Each step should have a clear thought explaining WHY we're calling this tool\n",
        "2. **Use Real Tool Names**: The tool_call.name must exactly match one of the available tools\n",
        "3. **Valid JSON Arguments**: The tool_call.arguments must be valid JSON matching the tool's parameter schema\n",
        "4. **Realistic IDs**: When referencing IDs discovered in previous steps, use placeholder format like \"00000001\"\n",
        "5. **Complete the Task**: The trajectory must fully solve the user's request\n",
        "6. **1-6 Steps**: Use the minimum number of steps needed. Simple tasks may need only 1 step.\n",
        "\n",
        "**Common Patterns:**\n",
        "- Look up a person's email before sending them a message\n",
        "- Search for records before updating/deleting them\n",
        "- Get information from one database to use in another\n",
        "- Some tasks can be completed in a single step (e.g., reply to an email, update an event)\n",
        "\n",
        "**Example Step:**\n",
        "{% raw %}\n",
        "```json\n",
        "{\n",
        "  \"step_number\": 1,\n",
        "  \"thought\": \"The user wants to email Raj, but I need his email address first. I'll look it up in the company directory.\",\n",
        "  \"tool_call\": {\n",
        "    \"name\": \"company_directory_find_email_address\",\n",
        "    \"arguments\": \"{\\\"name\\\": \\\"Raj\\\"}\"\n",
        "  },\n",
        "  \"expected_result\": \"Raj's email address (likely raj.patel@atlas.com)\"\n",
        "}\n",
        "```\n",
        "{% endraw %}\n",
        "\n",
        "Output the complete AgentTrajectory with all steps needed to solve the task.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Trajectory Simulation Prompt loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Query Judge Prompt loaded\n",
            "Trajectory Judge Prompt loaded\n"
          ]
        }
      ],
      "source": [
        "# Prompt 3a: Judge the quality of the generated USER QUERY\n",
        "USER_QUERY_JUDGE_PROMPT = \"\"\"\n",
        "You are a quality assurance judge evaluating a synthetically generated user query for training an AI workplace assistant.\n",
        "\n",
        "**Generated User Query:**\n",
        "{{ user_query }}\n",
        "\n",
        "**Available Tools (with full schemas):**\n",
        "{{ tools_json }}\n",
        "\n",
        "**Your Task:** Evaluate whether this user query is valid and achievable with the available tools.\n",
        "\n",
        "**CRITICAL - Check for Schema Compliance:**\n",
        "Many tools have RESTRICTED VALUES for certain fields. The user query must only reference values that are valid according to the tool schemas. For example:\n",
        "- If a tool says `list_name` must be one of 'Backlog', 'In Progress', 'In Review', 'Completed' - the query cannot ask for a \"Prospects\" list\n",
        "- If a tool says `board` must be one of 'Back end', 'Front end', 'Design' - the query cannot ask for a \"Sales\" board  \n",
        "- If a tool says `status` must be one of 'Qualified', 'Won', 'Lost', 'Lead', 'Proposal' - the query cannot use other statuses\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "\n",
        "1. **Feasibility (1-5)**: Can this request be fulfilled using the available tools?\n",
        "   - Score 1 if the request requires tools/capabilities that don't exist\n",
        "   - Score 5 if the request is fully achievable with available tools\n",
        "\n",
        "2. **Schema Compliance (1-5)**: Does the request use valid values?\n",
        "   - Score 1 if the query references invalid enum values (wrong board names, list names, statuses, etc.)\n",
        "   - Score 3 if the query is ambiguous but could map to valid values\n",
        "   - Score 5 if all referenced values exactly match valid options in tool schemas\n",
        "\n",
        "3. **Naturalness (1-5)**: Does this sound like a real user request?\n",
        "   - Score 1 if robotic or artificial sounding\n",
        "   - Score 5 if very natural and realistic\n",
        "\n",
        "**is_valid:** Set to False if feasibility < 3 OR schema_compliance < 3. These queries should be discarded.\n",
        "\n",
        "**issues:** List specific problems found. Examples:\n",
        "- \"References 'Sales' board but valid boards are: 'Back end', 'Front end', 'Design'\"\n",
        "- \"References 'Prospects' list but valid lists are: 'Backlog', 'In Progress', 'In Review', 'Completed'\"\n",
        "- \"None\" if no issues found\n",
        "\n",
        "**Output:** Return UserQueryJudgeScores with all fields.\n",
        "\"\"\"\n",
        "\n",
        "# Prompt 3b: Judge the quality of the generated TRAJECTORY\n",
        "TRAJECTORY_JUDGE_PROMPT = \"\"\"\n",
        "You are a quality assurance judge evaluating a generated trajectory (sequence of tool calls) for training an AI workplace assistant.\n",
        "\n",
        "**User Request:**\n",
        "{{ user_query }}\n",
        "\n",
        "**Generated Trajectory:**\n",
        "{{ trajectory }}\n",
        "\n",
        "**Available Tools (with full schemas):**\n",
        "{{ tools_json }}\n",
        "\n",
        "**Your Task:** Evaluate whether this trajectory correctly solves the user request using valid tool calls.\n",
        "\n",
        "**CRITICAL - Check for Argument Validity:**\n",
        "Tool arguments must use EXACTLY the values allowed by the tool schemas. For example:\n",
        "- `list_name` must be one of: 'Backlog', 'In Progress', 'In Review', 'Completed' (NOT 'Prospects', 'Todo', etc.)\n",
        "- `board` must be one of: 'Back end', 'Front end', 'Design' (NOT 'Sales', 'Marketing', etc.)\n",
        "- `status` must be one of: 'Qualified', 'Won', 'Lost', 'Lead', 'Proposal' (NOT 'Active', 'Prospect', etc.)\n",
        "- `product_interest` must be one of: 'Software', 'Hardware', 'Services', 'Consulting', 'Training'\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "\n",
        "1. **Tool Validity (1-5)**: Are all tool names correct?\n",
        "   - Score 1 if any tool name doesn't match available tools\n",
        "   - Score 5 if all tool names exactly match\n",
        "\n",
        "2. **Argument Validity (1-5)**: Are all arguments schema-compliant?\n",
        "   - Score 1 if any argument uses invalid enum values or wrong types\n",
        "   - Score 3 if arguments are mostly valid but some are ambiguous\n",
        "   - Score 5 if all arguments perfectly match the schema requirements\n",
        "\n",
        "3. **Completeness (1-5)**: Does the trajectory fully solve the request?\n",
        "   - Score 1 if major parts of the request are unaddressed\n",
        "   - Score 5 if the trajectory completely fulfills the request\n",
        "\n",
        "4. **Efficiency (1-5)**: Is the trajectory optimal?\n",
        "   - Score 1 if there are many unnecessary steps\n",
        "   - Score 5 if the trajectory is optimal with no wasted steps\n",
        "\n",
        "**is_valid:** Set to False if tool_validity < 4 OR argument_validity < 4. These trajectories have errors and should be discarded.\n",
        "\n",
        "**issues:** List specific problems found. Examples:\n",
        "- \"Step 2 uses list_name='Prospects' but valid values are: 'Backlog', 'In Progress', 'In Review', 'Completed'\"\n",
        "- \"Step 1 calls 'email_send' but correct tool name is 'email_send_email'\"\n",
        "- \"None\" if no issues found\n",
        "\n",
        "**Output:** Return TrajectoryJudgeScores with all fields.\n",
        "\"\"\"\n",
        "\n",
        "print(\"User Query Judge Prompt loaded\")\n",
        "print(\"Trajectory Judge Prompt loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Seed Data\n",
        "\n",
        "**Data Designer** works by expanding seed data through LLM generation. Each seed row provides context variables that get substituted into the prompt templates:\n",
        "\n",
        "- `category`: Which tool database to focus on (ensures diversity across domains)\n",
        "- `pattern`: Which multi-step pattern to use (e.g., lookup-then-send, search-then-update)\n",
        "- `tools_json`: Full tool schemas for the LLM to reference\n",
        "- `system_prompt`: The system context for the workplace assistant\n",
        "\n",
        "> **Pattern Engineering Note:** The multi-step patterns used as seeds in `create_seed_data()` are domain-informed. In practice, you can engineer these patterns from heuristics, inferred tool-call chains observed in production traffic, or other rule-based design choices. In this case, we had some common patterns stored in `tools/environments.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 50 seeds\n",
            "\n",
            "Sample seed:\n",
            "{'seed_id': 0, 'category': 'company_directory', 'pattern': \"lookup_then_send_email: Look up a person's email address, then send them an email\", 'tools_description': \"- **company_directory_find_email_address**: Finds all email addresses containing the given name (case-insensitive search).\\n  Parameters: ['name']\", 'tools_json': '[\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"company_directory_find_email_address\",\\n    \"description\": \"Finds all email addresses containing the given name (case-insensitive search).\",\\n    \"database\": \"company_directory\",\\n    \"operation_type\": \"read\",\\n    \"parameters\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"name\": {\\n          \"type\": \"string\",\\n          \"description\": \"Name or partial name to search for in email addresses\"\\n        }\\n      },\\n      \"required\": [],\\n      \"additionalProperties\": false\\n    },\\n    \"strict\": false\\n  }\\n]', 'tools_summary': '- **company_directory_find_email_address**: Finds all email addresses containing the given name (case-insensitive search).\\n- **email_get_email_information_by_id**: Retrieves specific details of an email by its ID.\\n- **email_search_emails**: Searches for emails matching the given query across subject, body, or sender fields. The function matches an email if all words in the query appear in any of these fields.\\n- **email_send_email**: Sends an email to the specified recipient.\\n- **email_delete_email**: Deletes an email by its ID.\\n- **email_forward_email**: Forwards an email to the specified recipient.\\n- **email_reply_email**: Replies to an email by its ID.\\n- **calendar_get_event_information_by_id**: Returns the event for a given ID.\\n- **calendar_search_events**: Returns the events for a given query with pagination support.\\n- **calendar_create_event**: Creates a new event.\\n- **calendar_delete_event**: Deletes an event.\\n- **calendar_update_event**: Updates an event.\\n- **analytics_get_visitor_information_by_id**: Returns the analytics data for a given visitor ID.\\n- **analytics_create_plot**: Plots the analytics data for a given time range and value.\\n- **analytics_total_visits_count**: Returns the total number of visits within a specified time range.\\n- **analytics_engaged_users_count**: Returns the number of engaged users within a specified time range.\\n- **analytics_traffic_source_count**: Returns the number of visits from a specific traffic source within a specified time range.\\n- **analytics_get_average_session_duration**: Returns the average session duration within a specified time range.\\n- **project_management_get_task_information_by_id**: Returns the task information for a given ID.\\n- **project_management_search_tasks**: Searches for tasks based on the given parameters.\\n- **project_management_create_task**: Creates a new task.\\n- **project_management_delete_task**: Deletes a task by ID.\\n- **project_management_update_task**: Updates a task by ID.\\n- **customer_relationship_manager_search_customers**: Searches for customers based on the given parameters with pagination support.\\n- **customer_relationship_manager_update_customer**: Updates a customer record by ID.\\n- **customer_relationship_manager_add_customer**: Adds a new customer record.\\n- **customer_relationship_manager_delete_customer**: Deletes a customer record by ID.', 'system_prompt': \"Today's date is Thursday, 2026-01-29 and the current time is 23:59:00. Remember the current date and time when answering queries. Meetings must not start before 9am or end after 6pm.\"}\n"
          ]
        }
      ],
      "source": [
        "def create_seed_data(num_seeds: int = 100) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create seed data for the Data Designer pipeline.\n",
        "    \n",
        "    Each seed contains:\n",
        "    - category: Which tool category to focus on\n",
        "    - pattern: Which multi-step pattern to use\n",
        "    - tools_description: Formatted tool descriptions\n",
        "    - tools_json: Full tool schemas as JSON\n",
        "    - system_prompt: The system context\n",
        "    \"\"\"\n",
        "    seeds = []\n",
        "    \n",
        "    categories = list(TOOL_CATEGORIES.keys())\n",
        "    patterns = [\n",
        "        f\"{p['pattern']}: {p['description']}\" for p in MULTI_STEP_PATTERNS\n",
        "    ]\n",
        "    \n",
        "    for i in range(num_seeds):\n",
        "        # Select category and pattern (ensuring diversity)\n",
        "        category = categories[i % len(categories)]\n",
        "        pattern = patterns[i % len(patterns)]\n",
        "        \n",
        "        # Get tools for this category (plus company_directory for lookups)\n",
        "        relevant_tool_names = TOOL_CATEGORIES[category] + TOOL_CATEGORIES.get('company_directory', [])\n",
        "        relevant_tools = [t for t in TOOLS if t['name'] in relevant_tool_names]\n",
        "        \n",
        "        seeds.append({\n",
        "            'seed_id': i,\n",
        "            'category': category,\n",
        "            'pattern': pattern,\n",
        "            'tools_description': format_tools_for_prompt(relevant_tools, include_schemas=True),\n",
        "            'tools_json': json.dumps(relevant_tools, indent=2),\n",
        "            'tools_summary': format_tools_for_prompt(TOOLS),  # All tools for judge\n",
        "            'system_prompt': SYSTEM_PROMPT,\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(seeds)\n",
        "\n",
        "# Create seed data\n",
        "seed_df = create_seed_data(num_seeds=50)\n",
        "print(f\"Created {len(seed_df)} seeds\")\n",
        "print(f\"\\nSample seed:\")\n",
        "print(seed_df.iloc[0].to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the seed data as a Parquet file for Data Designer to consume."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seeds saved to workplace_assistant_seeds.parquet\n"
          ]
        }
      ],
      "source": [
        "# Save seeds to parquet for Data Designer\n",
        "seed_df.to_parquet('workplace_assistant_seeds.parquet', index=False)\n",
        "print(\"Seeds saved to workplace_assistant_seeds.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Configure the Data Designer Pipeline\n",
        "\n",
        "Now we wire everything together into a **Data Designer** workflow:\n",
        "\n",
        "1. **Load Seeds** — Provides category, pattern, and tools for each generation\n",
        "2. **Generate User Query** — LLM creates a realistic workplace request\n",
        "3. **Judge User Query** — LLM validates feasibility and schema compliance\n",
        "4. **Simulate Trajectory** — LLM generates the step-by-step tool-call solution\n",
        "5. **Judge Trajectory** — LLM validates tool names and argument correctness\n",
        "\n",
        "### Configuration\n",
        "\n",
        "First, set up the **NVIDIA Inference API** provider and model. The API key is read from the `NVIDIA_API_KEY` environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "if \"NVIDIA_API_KEY\" not in os.environ or not os.environ[\"NVIDIA_API_KEY\"]:\n",
        "    os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter your NVIDIA API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define custom provider pointing to NVIDIA Inference API\n",
        "NVIDIA_INFERENCE_URL = \"https://inference-api.nvidia.com/v1\"\n",
        "\n",
        "custom_providers = [\n",
        "    ModelProvider(\n",
        "        name=\"nvidia-inference\",\n",
        "        endpoint=NVIDIA_INFERENCE_URL,\n",
        "        provider_type=\"openai\",\n",
        "        api_key=os.environ.get(\"NVIDIA_API_KEY\", \"\"),\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Model name must match NVIDIA's model identifier\n",
        "MODEL_ID = \"nvidia/openai/gpt-oss-120b\"\n",
        "MODEL_ALIAS = \"gpt-oss-120b\"\n",
        "\n",
        "model_configs = [\n",
        "    ModelConfig(\n",
        "        alias=MODEL_ALIAS,\n",
        "        model=MODEL_ID,\n",
        "        provider=\"nvidia-inference\",\n",
        "        inference_parameters=ChatCompletionInferenceParams(\n",
        "            max_tokens=16384,\n",
        "        ),\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize DataDesigner and config builder\n",
        "data_designer = DataDesigner(model_providers=custom_providers)\n",
        "config_builder = DataDesignerConfigBuilder(model_configs=model_configs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build the pipeline with four generation columns: user query, user query judge, trajectory, and trajectory judge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline configured with 4 generation columns:\n",
            "  1. user_query (text) - Generate realistic user request\n",
            "  2. user_query_judge (structured) - Validate query feasibility and schema compliance\n",
            "  3. trajectory (structured) - Generate step-by-step solution\n",
            "  4. trajectory_judge (structured) - Validate tool calls and argument values\n"
          ]
        }
      ],
      "source": [
        "def build_workplace_assistant_pipeline():\n",
        "    \"\"\"\n",
        "    Build the complete Data Designer pipeline for generating \n",
        "    multi-step tool-calling training data.\n",
        "    \n",
        "    Pipeline stages:\n",
        "    1. Generate user query\n",
        "    2. Judge user query (filter invalid queries early)\n",
        "    3. Generate trajectory \n",
        "    4. Judge trajectory (filter invalid trajectories)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize the config builder\n",
        "    config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n",
        "    \n",
        "    # Load seed data\n",
        "    seed_ref = LocalFileSeedSource(path='workplace_assistant_seeds.parquet')\n",
        "    config_builder.with_seed_dataset(seed_ref, sampling_strategy=SamplingStrategy.SHUFFLE)\n",
        "    \n",
        "    # Column 1: Generate User Query\n",
        "    # This creates a realistic workplace request based on the category and pattern\n",
        "    config_builder.add_column(\n",
        "        LLMTextColumnConfig(\n",
        "            name=\"user_query\",\n",
        "            prompt=USER_QUERY_GENERATION_PROMPT,\n",
        "            model_alias=MODEL_ALIAS,\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # Column 2: Judge User Query\n",
        "    # Validates that the user query is feasible and uses valid enum values\n",
        "    config_builder.add_column(\n",
        "        LLMStructuredColumnConfig(\n",
        "            name=\"user_query_judge\",\n",
        "            prompt=USER_QUERY_JUDGE_PROMPT,\n",
        "            output_format=UserQueryJudgeScores,\n",
        "            model_alias=MODEL_ALIAS,\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # Column 3: Simulate Agent Trajectory\n",
        "    # This generates the step-by-step solution with tool calls\n",
        "    config_builder.add_column(\n",
        "        LLMStructuredColumnConfig(\n",
        "            name=\"trajectory\",\n",
        "            prompt=TRAJECTORY_SIMULATION_PROMPT,\n",
        "            output_format=AgentTrajectory,\n",
        "            model_alias=MODEL_ALIAS,\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # Column 4: Judge Trajectory\n",
        "    # Validates that the trajectory uses correct tool names and valid argument values\n",
        "    config_builder.add_column(\n",
        "        LLMStructuredColumnConfig(\n",
        "            name=\"trajectory_judge\",\n",
        "            prompt=TRAJECTORY_JUDGE_PROMPT,\n",
        "            output_format=TrajectoryJudgeScores,\n",
        "            model_alias=MODEL_ALIAS,\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    return config_builder\n",
        "\n",
        "# Build the pipeline\n",
        "pipeline = build_workplace_assistant_pipeline()\n",
        "print(\"Pipeline configured with 4 generation columns:\")\n",
        "print(\"  1. user_query (text) - Generate realistic user request\")\n",
        "print(\"  2. user_query_judge (structured) - Validate query feasibility and schema compliance\")\n",
        "print(\"  3. trajectory (structured) - Generate step-by-step solution\")\n",
        "print(\"  4. trajectory_judge (structured) - Validate tool calls and argument values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validate the pipeline configuration to catch any issues before generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13:51:08] [INFO] ✅ Validation passed\n"
          ]
        }
      ],
      "source": [
        "data_designer.validate(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a quick preview with 2 records to verify the pipeline produces well-formed outputs before scaling up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13:51:12] [INFO] 📸 Preview generation in progress\n",
            "[13:51:12] [INFO] ✅ Validation passed\n",
            "[13:51:12] [INFO] ⛓️ Sorting column configs into a Directed Acyclic Graph\n",
            "[13:51:12] [INFO] 🩺 Running health checks for models...\n",
            "[13:51:12] [INFO]   |-- 👀 Checking 'nvidia/openai/gpt-oss-120b' in provider named 'nvidia-inference' for model alias 'gpt-oss-120b'...\n",
            "[13:51:14] [INFO]   |-- ✅ Passed!\n",
            "[13:51:14] [INFO] 🌱 Sampling 2 records from seed dataset\n",
            "[13:51:14] [INFO]   |-- seed dataset size: 50 records\n",
            "[13:51:14] [INFO]   |-- sampling strategy: shuffle\n",
            "[13:51:14] [INFO] llm-text model configuration for generating column 'user_query'\n",
            "[13:51:14] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[13:51:14] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[13:51:14] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[13:51:14] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[13:51:14] [INFO] 🐙 Processing llm-text column 'user_query' with 4 concurrent workers\n",
            "[13:51:20] [INFO] llm-structured model configuration for generating column 'user_query_judge'\n",
            "[13:51:20] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[13:51:20] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[13:51:20] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[13:51:20] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[13:51:20] [INFO] 🐙 Processing llm-structured column 'user_query_judge' with 4 concurrent workers\n",
            "[13:51:24] [INFO] llm-structured model configuration for generating column 'trajectory'\n",
            "[13:51:24] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[13:51:24] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[13:51:24] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[13:51:24] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[13:51:24] [INFO] 🐙 Processing llm-structured column 'trajectory' with 4 concurrent workers\n",
            "[13:51:31] [INFO] llm-structured model configuration for generating column 'trajectory_judge'\n",
            "[13:51:31] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[13:51:31] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[13:51:31] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[13:51:31] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[13:51:31] [INFO] 🐙 Processing llm-structured column 'trajectory_judge' with 4 concurrent workers\n",
            "[13:51:35] [INFO] 📊 Model usage summary:\n",
            "{\n",
            "    \"nvidia/openai/gpt-oss-120b\": {\n",
            "        \"token_usage\": {\n",
            "            \"input_tokens\": 16019,\n",
            "            \"output_tokens\": 5904,\n",
            "            \"total_tokens\": 21923\n",
            "        },\n",
            "        \"request_usage\": {\n",
            "            \"successful_requests\": 8,\n",
            "            \"failed_requests\": 0,\n",
            "            \"total_requests\": 8\n",
            "        },\n",
            "        \"tokens_per_second\": 1026,\n",
            "        \"requests_per_minute\": 22\n",
            "    }\n",
            "}\n",
            "[13:51:35] [INFO] 📐 Measuring dataset column statistics:\n",
            "[13:51:35] [INFO]   |-- 📝 column: 'user_query'\n",
            "[13:51:35] [INFO]   |-- 🗂️ column: 'user_query_judge'\n",
            "[13:51:35] [INFO]   |-- 🗂️ column: 'trajectory'\n",
            "[13:51:35] [INFO]   |-- 🗂️ column: 'trajectory_judge'\n",
            "[13:51:35] [INFO] 🏆 Preview complete!\n"
          ]
        }
      ],
      "source": [
        "preview = data_designer.preview(pipeline, num_records=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect a sample generated user query from the preview."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed_id</th>\n",
              "      <th>category</th>\n",
              "      <th>pattern</th>\n",
              "      <th>tools_description</th>\n",
              "      <th>tools_json</th>\n",
              "      <th>tools_summary</th>\n",
              "      <th>system_prompt</th>\n",
              "      <th>user_query</th>\n",
              "      <th>user_query__reasoning_trace</th>\n",
              "      <th>user_query_judge</th>\n",
              "      <th>user_query_judge__reasoning_trace</th>\n",
              "      <th>trajectory</th>\n",
              "      <th>trajectory__reasoning_trace</th>\n",
              "      <th>trajectory_judge</th>\n",
              "      <th>trajectory_judge__reasoning_trace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47</td>\n",
              "      <td>customer_relationship_manager</td>\n",
              "      <td>search_then_batch_update_customers: Search for...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>[\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
              "      <td>Please reassign all of my Qualified customers ...</td>\n",
              "      <td>We need to produce a realistic user request th...</td>\n",
              "      <td>{'feasibility': 5, 'schema_compliance': 5, 'na...</td>\n",
              "      <td>We need to evaluate the user query: \"Please re...</td>\n",
              "      <td>{'reasoning_trace': [{'step_number': 1, 'thoug...</td>\n",
              "      <td>We need to produce a trajectory of steps to re...</td>\n",
              "      <td>{'tool_validity': 5, 'argument_validity': 5, '...</td>\n",
              "      <td>We need to evaluate the generated trajectory.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32</td>\n",
              "      <td>calendar</td>\n",
              "      <td>get_email_info_then_forward: Get specific info...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>[\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
              "      <td>Can you pull the details of the \"Project Kicko...</td>\n",
              "      <td>We need generate a realistic user request that...</td>\n",
              "      <td>{'feasibility': 5, 'schema_compliance': 5, 'na...</td>\n",
              "      <td>We need to evaluate the user query: \"Can you p...</td>\n",
              "      <td>{'reasoning_trace': [{'step_number': 1, 'thoug...</td>\n",
              "      <td>We need to produce trajectory steps to accompl...</td>\n",
              "      <td>{'tool_validity': 5, 'argument_validity': 5, '...</td>\n",
              "      <td>We need to evaluate the generated trajectory.\\...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   seed_id                       category  \\\n",
              "0       47  customer_relationship_manager   \n",
              "1       32                       calendar   \n",
              "\n",
              "                                             pattern  \\\n",
              "0  search_then_batch_update_customers: Search for...   \n",
              "1  get_email_info_then_forward: Get specific info...   \n",
              "\n",
              "                                   tools_description  \\\n",
              "0  - **company_directory_find_email_address**: Fi...   \n",
              "1  - **company_directory_find_email_address**: Fi...   \n",
              "\n",
              "                                          tools_json  \\\n",
              "0  [\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...   \n",
              "1  [\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...   \n",
              "\n",
              "                                       tools_summary  \\\n",
              "0  - **company_directory_find_email_address**: Fi...   \n",
              "1  - **company_directory_find_email_address**: Fi...   \n",
              "\n",
              "                                       system_prompt  \\\n",
              "0  Today's date is Thursday, 2026-01-29 and the c...   \n",
              "1  Today's date is Thursday, 2026-01-29 and the c...   \n",
              "\n",
              "                                          user_query  \\\n",
              "0  Please reassign all of my Qualified customers ...   \n",
              "1  Can you pull the details of the \"Project Kicko...   \n",
              "\n",
              "                         user_query__reasoning_trace  \\\n",
              "0  We need to produce a realistic user request th...   \n",
              "1  We need generate a realistic user request that...   \n",
              "\n",
              "                                    user_query_judge  \\\n",
              "0  {'feasibility': 5, 'schema_compliance': 5, 'na...   \n",
              "1  {'feasibility': 5, 'schema_compliance': 5, 'na...   \n",
              "\n",
              "                   user_query_judge__reasoning_trace  \\\n",
              "0  We need to evaluate the user query: \"Please re...   \n",
              "1  We need to evaluate the user query: \"Can you p...   \n",
              "\n",
              "                                          trajectory  \\\n",
              "0  {'reasoning_trace': [{'step_number': 1, 'thoug...   \n",
              "1  {'reasoning_trace': [{'step_number': 1, 'thoug...   \n",
              "\n",
              "                         trajectory__reasoning_trace  \\\n",
              "0  We need to produce a trajectory of steps to re...   \n",
              "1  We need to produce trajectory steps to accompl...   \n",
              "\n",
              "                                    trajectory_judge  \\\n",
              "0  {'tool_validity': 5, 'argument_validity': 5, '...   \n",
              "1  {'tool_validity': 5, 'argument_validity': 5, '...   \n",
              "\n",
              "                   trajectory_judge__reasoning_trace  \n",
              "0  We need to evaluate the generated trajectory.\\...  \n",
              "1  We need to evaluate the generated trajectory.\\...  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preview.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Please reassign all of my Qualified customers who are interested in Consulting and whose last contact date is before 2024-01-01 to Maria Lopez (maria.lopez@company.com) and set their follow‑up date to 2024-03-01.',\n",
              " {'reasoning_trace': [{'step_number': 1,\n",
              "    'thought': 'First I need to find all customers that match the criteria: status Qualified, product_interest Consulting, and last_contact_date before 2024-01-01. I will search the CRM with these filters.',\n",
              "    'tool_call': {'name': 'customer_relationship_manager_search_customers',\n",
              "     'arguments': '{\"status\": \"Qualified\", \"product_interest\": \"Consulting\", \"last_contact_date_max\": \"2023-12-31\", \"page\": 1, \"page_size\": 50}'},\n",
              "    'expected_result': 'A list of customer records that satisfy the criteria, including their customer_id values (e.g., 11111111 and 22222222).'},\n",
              "   {'step_number': 2,\n",
              "    'thought': 'Reassign the first matching customer (ID 11111111) to Maria Lopez by updating the assigned_to_email field.',\n",
              "    'tool_call': {'name': 'customer_relationship_manager_update_customer',\n",
              "     'arguments': '{\"customer_id\": \"11111111\", \"field\": \"assigned_to_email\", \"new_value\": \"maria.lopez@company.com\"}'},\n",
              "    'expected_result': 'Customer 11111111 now has assigned_to_email set to maria.lopez@company.com.'},\n",
              "   {'step_number': 3,\n",
              "    'thought': 'Set the follow‑up date for the same customer (ID 11111111) to 2024-03-01.',\n",
              "    'tool_call': {'name': 'customer_relationship_manager_update_customer',\n",
              "     'arguments': '{\"customer_id\": \"11111111\", \"field\": \"follow_up_by\", \"new_value\": \"2024-03-01\"}'},\n",
              "    'expected_result': 'Customer 11111111 now has follow_up_by set to 2024-03-01.'},\n",
              "   {'step_number': 4,\n",
              "    'thought': 'Reassign the second matching customer (ID 22222222) to Maria Lopez.',\n",
              "    'tool_call': {'name': 'customer_relationship_manager_update_customer',\n",
              "     'arguments': '{\"customer_id\": \"22222222\", \"field\": \"assigned_to_email\", \"new_value\": \"maria.lopez@company.com\"}'},\n",
              "    'expected_result': 'Customer 22222222 now has assigned_to_email set to maria.lopez@company.com.'},\n",
              "   {'step_number': 5,\n",
              "    'thought': 'Set the follow‑up date for the second customer (ID 22222222) to 2024-03-01.',\n",
              "    'tool_call': {'name': 'customer_relationship_manager_update_customer',\n",
              "     'arguments': '{\"customer_id\": \"22222222\", \"field\": \"follow_up_by\", \"new_value\": \"2024-03-01\"}'},\n",
              "    'expected_result': 'Customer 22222222 now has follow_up_by set to 2024-03-01.'}],\n",
              "  'final_answer': 'All Qualified customers interested in Consulting with a last contact date before 2024‑01‑01 have been reassigned to Maria Lopez (maria.lopez@company.com) and their follow‑up dates have been set to 2024‑03‑01.'})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preview.dataset.user_query[0], preview.dataset.trajectory[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Set Up Quality Filtering (Generic)\n",
        "\n",
        "Before any downstream format conversion, we apply dual-level quality filtering to keep only high-quality examples.\n",
        "\n",
        "This stage is generic to **Data Designer** workflows and not specific to NeMo Gym.\n",
        "\n",
        "To keep this notebook clean, quality filtering helpers live in `utils/quality_filtering.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quality filtering utility loaded.\n",
            "\n",
            "Quickstart:\n",
            "1) Inspect rejection reasons:\n",
            "   show_rejection_reasons(results_df, num_examples=3)\n",
            "2) Filter with default strict thresholds:\n",
            "   filtered_df = filter_high_quality(results_df, verbose=True)\n",
            "3) Customize thresholds (optional):\n",
            "   thresholds = FilterThresholds(min_query_schema_compliance=5)\n",
            "   filtered_df = filter_high_quality(results_df, **thresholds.to_kwargs())\n"
          ]
        }
      ],
      "source": [
        "from utils.quality_filtering import (\n",
        "    FilterThresholds,\n",
        "    filter_high_quality,\n",
        "    print_quality_filtering_quickstart,\n",
        "    show_rejection_reasons,\n",
        ")\n",
        "\n",
        "# This keeps notebook cells lightweight and points users to the utility API.\n",
        "print_quality_filtering_quickstart()\n",
        "\n",
        "# Optional: define reusable custom thresholds for stricter/looser filtering.\n",
        "# custom_thresholds = FilterThresholds(min_query_schema_compliance=5)\n",
        "# filtered_df = filter_high_quality(results_df, **custom_thresholds.to_kwargs(), verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Generate and Filter the Dataset\n",
        "\n",
        "Run the full pipeline end-to-end: generate records and apply **dual-level quality filtering**.\n",
        "\n",
        "```\n",
        "┌──────────────┐    ┌──────────────┐    ┌──────────────┐    ┌──────────────┐\n",
        "│   Generate   │───▶│ Stage 1:     │───▶│ Stage 2:     │───▶│   Filtered   │\n",
        "│   Records    │    │ Query Judge  │    │ Traj Judge   │    │   Dataset    │\n",
        "└──────────────┘    └──────────────┘    └──────────────┘    └──────────────┘\n",
        "```\n",
        "\n",
        "**Utility location:** `utils/quality_filtering.py`\n",
        "\n",
        "**Quick usage:**\n",
        "- Run `show_rejection_reasons(results_df, num_examples=3)` to inspect failures\n",
        "- Run `filter_high_quality(results_df, verbose=True)` to apply default strict filtering\n",
        "- Optionally tune thresholds with `FilterThresholds(...).to_kwargs()`\n",
        "\n",
        "**Why Dual-Level Filtering?**\n",
        "- **Stage 1 (User Query)**: Catches queries like which are intractable in this context.\n",
        "- **Stage 2 (Trajectory)**: Catches tool argument errors that slipped through, or that doesn't answer the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[14:43:34] [INFO] 🎨 Creating Data Designer dataset\n",
            "[14:43:34] [INFO] ✅ Validation passed\n",
            "[14:43:34] [INFO] ⛓️ Sorting column configs into a Directed Acyclic Graph\n",
            "[14:43:34] [INFO] 📂 Dataset path '/Users/shashankv/Documents/Work/workplace-asst-sdg/DataDesigner/docs/colab_notebooks/workplace_assistant/artifacts/dataset' already exists. Dataset from this session\n",
            "\t\t     will be saved to '/Users/shashankv/Documents/Work/workplace-asst-sdg/DataDesigner/docs/colab_notebooks/workplace_assistant/artifacts/dataset_02-12-2026_144334' instead.\n",
            "[14:43:34] [INFO] 🩺 Running health checks for models...\n",
            "[14:43:34] [INFO]   |-- 👀 Checking 'nvidia/openai/gpt-oss-120b' in provider named 'nvidia-inference' for model alias 'gpt-oss-120b'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 10 examples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[14:43:34] [INFO]   |-- ✅ Passed!\n",
            "[14:43:34] [INFO] ⏳ Processing batch 1 of 1\n",
            "[14:43:34] [INFO] 🌱 Sampling 10 records from seed dataset\n",
            "[14:43:34] [INFO]   |-- seed dataset size: 50 records\n",
            "[14:43:34] [INFO]   |-- sampling strategy: shuffle\n",
            "[14:43:34] [INFO] llm-text model configuration for generating column 'user_query'\n",
            "[14:43:34] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[14:43:34] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[14:43:34] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[14:43:34] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[14:43:34] [INFO] 🐙 Processing llm-text column 'user_query' with 4 concurrent workers\n",
            "[14:43:47] [INFO] llm-structured model configuration for generating column 'user_query_judge'\n",
            "[14:43:47] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[14:43:47] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[14:43:47] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[14:43:47] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[14:43:47] [INFO] 🐙 Processing llm-structured column 'user_query_judge' with 4 concurrent workers\n",
            "[14:43:52] [INFO] llm-structured model configuration for generating column 'trajectory'\n",
            "[14:43:52] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[14:43:52] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[14:43:52] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[14:43:52] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[14:43:52] [INFO] 🐙 Processing llm-structured column 'trajectory' with 4 concurrent workers\n",
            "[14:44:11] [INFO] llm-structured model configuration for generating column 'trajectory_judge'\n",
            "[14:44:11] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
            "[14:44:11] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
            "[14:44:11] [INFO]   |-- model provider: 'nvidia-inference'\n",
            "[14:44:11] [INFO]   |-- inference parameters: generation_type=chat-completion, max_parallel_requests=4, max_tokens=16384\n",
            "[14:44:11] [INFO] 🐙 Processing llm-structured column 'trajectory_judge' with 4 concurrent workers\n",
            "[14:44:23] [INFO] 📊 Model usage summary:\n",
            "{\n",
            "    \"nvidia/openai/gpt-oss-120b\": {\n",
            "        \"token_usage\": {\n",
            "            \"input_tokens\": 79976,\n",
            "            \"output_tokens\": 25536,\n",
            "            \"total_tokens\": 105512\n",
            "        },\n",
            "        \"request_usage\": {\n",
            "            \"successful_requests\": 40,\n",
            "            \"failed_requests\": 0,\n",
            "            \"total_requests\": 40\n",
            "        },\n",
            "        \"tokens_per_second\": 2179,\n",
            "        \"requests_per_minute\": 49\n",
            "    }\n",
            "}\n",
            "[14:44:23] [INFO] 📐 Measuring dataset column statistics:\n",
            "[14:44:23] [INFO]   |-- 📝 column: 'user_query'\n",
            "[14:44:23] [INFO]   |-- 🗂️ column: 'user_query_judge'\n",
            "[14:44:23] [INFO]   |-- 🗂️ column: 'trajectory'\n",
            "[14:44:23] [INFO]   |-- 🗂️ column: 'trajectory_judge'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated 10 records\n",
            "\n",
            "Columns: ['seed_id', 'category', 'pattern', 'tools_description', 'tools_json', 'tools_summary', 'system_prompt', 'user_query', 'user_query__reasoning_trace', 'user_query_judge', 'user_query_judge__reasoning_trace', 'trajectory', 'trajectory__reasoning_trace', 'trajectory_judge', 'trajectory_judge__reasoning_trace']\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating 10 examples...\")\n",
        "results = data_designer.create(pipeline, num_records=10)\n",
        "\n",
        "results_df = results.load_dataset()\n",
        "print(f\"\\nGenerated {len(results_df)} records\")\n",
        "print(\"\\nColumns:\", list(results_df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inspect rejection reasons at both judge levels to understand what kinds of errors the pipeline catches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 1: USER QUERY ISSUES\n",
            "======================================================================\n",
            "\n",
            "[INVALID QUERIES] (1 total)\n",
            "\n",
            "  [1] Query: Please find the most recent email from Acme Corporation about their interest in ...\n",
            "      Feasibility: 1/5 | Schema: 5/5\n",
            "      Issues: No available tool can search for or retrieve email messages, nor forward them; the request cannot be fulfilled with the provided functions.\n",
            "\n",
            "======================================================================\n",
            "STAGE 2: TRAJECTORY ISSUES\n",
            "======================================================================\n",
            "\n",
            "  No trajectory issues found!\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "show_rejection_reasons(results_df, num_examples=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply dual-level filtering with strict schema compliance requirements. Records must pass **both** the user query judge and the trajectory judge to be kept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "DUAL-LEVEL QUALITY FILTERING RESULTS\n",
            "======================================================================\n",
            "\n",
            "Total records: 10\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "STAGE 1: USER QUERY FILTERING\n",
            "----------------------------------------------------------------------\n",
            "  is_valid=True:                    9 / 10 ( 90.0%)\n",
            "  feasibility >= 3:              9 / 10 ( 90.0%)\n",
            "  schema_compliance >= 4:       10 / 10 (100.0%)\n",
            "  naturalness >= 3:             10 / 10 (100.0%)\n",
            "  ----------------------------------------------\n",
            "  PASSED Stage 1:                   9 / 10 ( 90.0%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "STAGE 2: TRAJECTORY FILTERING\n",
            "----------------------------------------------------------------------\n",
            "  is_valid=True:                   10 / 10 (100.0%)\n",
            "  tool_validity >= 4:          10 / 10 (100.0%)\n",
            "  argument_validity >= 4:      10 / 10 (100.0%)\n",
            "  completeness >= 3:            4 / 10 ( 40.0%)\n",
            "  efficiency >= 3:              9 / 10 ( 90.0%)\n",
            "  ----------------------------------------------\n",
            "  PASSED Stage 2:                   4 / 10 ( 40.0%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "REJECTION BREAKDOWN\n",
            "----------------------------------------------------------------------\n",
            "  Rejected by Query Judge only:         0\n",
            "  Rejected by Trajectory Judge only:    5\n",
            "  Rejected by BOTH judges:              1\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULT: 4 / 10 passed (40.0%)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "filtered_df = filter_high_quality(\n",
        "    results_df,\n",
        "    min_query_feasibility=3,\n",
        "    min_query_schema_compliance=4,\n",
        "    min_query_naturalness=3,\n",
        "    min_trajectory_tool_validity=4,\n",
        "    min_trajectory_argument_validity=4,\n",
        "    min_trajectory_completeness=3,\n",
        "    min_trajectory_efficiency=3,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STAGE 1: USER QUERY ISSUES\n",
            "======================================================================\n",
            "\n",
            "  No user query issues found!\n",
            "\n",
            "======================================================================\n",
            "STAGE 2: TRAJECTORY ISSUES\n",
            "======================================================================\n",
            "\n",
            "  No trajectory issues found!\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "show_rejection_reasons(filtered_df, num_examples=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9 (Optional): Convert to NeMo Gym Format and Save\n",
        "\n",
        "If you plan to use this data with **NeMo Gym**, convert filtered records into NeMo Gym JSONL format and save them.\n",
        "\n",
        "This conversion is NeMo Gym-specific and optional for generic Data Designer workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "convert_to_nemo_gym_format utility loaded.\n",
            "\n",
            "Quickstart:\n",
            "1) Build a converter tied to your tools + system prompt:\n",
            "   convert_fn = build_nemo_gym_converter(tools=TOOLS, system_prompt=SYSTEM_PROMPT)\n",
            "2) Save any filtered dataframe to JSONL:\n",
            "   save_for_nemo_gym(filtered_df, 'workplace_assistant_train.jsonl', convert_fn)\n",
            "Saved 4 examples to workplace_assistant_train-gpt-oss.jsonl\n",
            "\n",
            "Sample generated data (passed both quality stages):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed_id</th>\n",
              "      <th>category</th>\n",
              "      <th>pattern</th>\n",
              "      <th>tools_description</th>\n",
              "      <th>tools_json</th>\n",
              "      <th>tools_summary</th>\n",
              "      <th>system_prompt</th>\n",
              "      <th>user_query</th>\n",
              "      <th>user_query__reasoning_trace</th>\n",
              "      <th>user_query_judge</th>\n",
              "      <th>user_query_judge__reasoning_trace</th>\n",
              "      <th>trajectory</th>\n",
              "      <th>trajectory__reasoning_trace</th>\n",
              "      <th>trajectory_judge</th>\n",
              "      <th>trajectory_judge__reasoning_trace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>email</td>\n",
              "      <td>lookup_then_create_task: Look up a person's em...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>[\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
              "      <td>Can you find Marco Alvarez’s email address and...</td>\n",
              "      <td>The user wants a realistic user request that r...</td>\n",
              "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
              "      <td>We need to evaluate the user query: \"Can you f...</td>\n",
              "      <td>{'final_answer': \"Marco Alvarez's email was fo...</td>\n",
              "      <td>We need to produce a trajectory: find Marco Al...</td>\n",
              "      <td>{'argument_validity': 5, 'completeness': 5, 'e...</td>\n",
              "      <td>We need to evaluate the generated trajectory.\n",
              "...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>project_management</td>\n",
              "      <td>compare_traffic_sources: Compare multiple traf...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>[\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
              "      <td>I need to take over Jason Lee’s pending design...</td>\n",
              "      <td>We need to produce a realistic user request th...</td>\n",
              "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
              "      <td>We need to evaluate the user query: \"I need to...</td>\n",
              "      <td>{'final_answer': \"All of Jason Lee's pending d...</td>\n",
              "      <td>We need to produce a trajectory of steps to mo...</td>\n",
              "      <td>{'argument_validity': 5, 'completeness': 3, 'e...</td>\n",
              "      <td>We need to evaluate the trajectory.\n",
              "\n",
              "User requ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>analytics</td>\n",
              "      <td>multiple_analytics_queries: Query multiple ana...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>[\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
              "      <td>Could you pull the total number of website vis...</td>\n",
              "      <td>We need to generate a realistic user request t...</td>\n",
              "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
              "      <td>We need to evaluate query: \"Could you pull tot...</td>\n",
              "      <td>{'final_answer': 'Collected total visits, enga...</td>\n",
              "      <td>The user asks: pull total number of website vi...</td>\n",
              "      <td>{'argument_validity': 5, 'completeness': 5, 'e...</td>\n",
              "      <td>We need to evaluate the trajectory.\n",
              "\n",
              "User requ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>email</td>\n",
              "      <td>lookup_then_forward_email: Search for an email...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>[\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...</td>\n",
              "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
              "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
              "      <td>Please locate the email Jane Patel sent on Mar...</td>\n",
              "      <td>We need to produce a realistic user request th...</td>\n",
              "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
              "      <td>We need to evaluate the user query: \"Please lo...</td>\n",
              "      <td>{'final_answer': 'The email from Jane Patel da...</td>\n",
              "      <td>We need to produce a trajectory with steps to ...</td>\n",
              "      <td>{'argument_validity': 5, 'completeness': 4, 'e...</td>\n",
              "      <td>We need to evaluate the trajectory.\n",
              "\n",
              "User requ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   seed_id            category  \\\n",
              "0       13               email   \n",
              "1       40  project_management   \n",
              "2        9           analytics   \n",
              "3        1               email   \n",
              "\n",
              "                                             pattern  \\\n",
              "0  lookup_then_create_task: Look up a person's em...   \n",
              "1  compare_traffic_sources: Compare multiple traf...   \n",
              "2  multiple_analytics_queries: Query multiple ana...   \n",
              "3  lookup_then_forward_email: Search for an email...   \n",
              "\n",
              "                                   tools_description  \\\n",
              "0  - **company_directory_find_email_address**: Fi...   \n",
              "1  - **company_directory_find_email_address**: Fi...   \n",
              "2  - **company_directory_find_email_address**: Fi...   \n",
              "3  - **company_directory_find_email_address**: Fi...   \n",
              "\n",
              "                                          tools_json  \\\n",
              "0  [\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...   \n",
              "1  [\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...   \n",
              "2  [\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...   \n",
              "3  [\n",
              "  {\n",
              "    \"type\": \"function\",\n",
              "    \"name\": \"com...   \n",
              "\n",
              "                                       tools_summary  \\\n",
              "0  - **company_directory_find_email_address**: Fi...   \n",
              "1  - **company_directory_find_email_address**: Fi...   \n",
              "2  - **company_directory_find_email_address**: Fi...   \n",
              "3  - **company_directory_find_email_address**: Fi...   \n",
              "\n",
              "                                       system_prompt  \\\n",
              "0  Today's date is Thursday, 2026-01-29 and the c...   \n",
              "1  Today's date is Thursday, 2026-01-29 and the c...   \n",
              "2  Today's date is Thursday, 2026-01-29 and the c...   \n",
              "3  Today's date is Thursday, 2026-01-29 and the c...   \n",
              "\n",
              "                                          user_query  \\\n",
              "0  Can you find Marco Alvarez’s email address and...   \n",
              "1  I need to take over Jason Lee’s pending design...   \n",
              "2  Could you pull the total number of website vis...   \n",
              "3  Please locate the email Jane Patel sent on Mar...   \n",
              "\n",
              "                         user_query__reasoning_trace  \\\n",
              "0  The user wants a realistic user request that r...   \n",
              "1  We need to produce a realistic user request th...   \n",
              "2  We need to generate a realistic user request t...   \n",
              "3  We need to produce a realistic user request th...   \n",
              "\n",
              "                                    user_query_judge  \\\n",
              "0  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
              "1  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
              "2  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
              "3  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
              "\n",
              "                   user_query_judge__reasoning_trace  \\\n",
              "0  We need to evaluate the user query: \"Can you f...   \n",
              "1  We need to evaluate the user query: \"I need to...   \n",
              "2  We need to evaluate query: \"Could you pull tot...   \n",
              "3  We need to evaluate the user query: \"Please lo...   \n",
              "\n",
              "                                          trajectory  \\\n",
              "0  {'final_answer': \"Marco Alvarez's email was fo...   \n",
              "1  {'final_answer': \"All of Jason Lee's pending d...   \n",
              "2  {'final_answer': 'Collected total visits, enga...   \n",
              "3  {'final_answer': 'The email from Jane Patel da...   \n",
              "\n",
              "                         trajectory__reasoning_trace  \\\n",
              "0  We need to produce a trajectory: find Marco Al...   \n",
              "1  We need to produce a trajectory of steps to mo...   \n",
              "2  The user asks: pull total number of website vi...   \n",
              "3  We need to produce a trajectory with steps to ...   \n",
              "\n",
              "                                    trajectory_judge  \\\n",
              "0  {'argument_validity': 5, 'completeness': 5, 'e...   \n",
              "1  {'argument_validity': 5, 'completeness': 3, 'e...   \n",
              "2  {'argument_validity': 5, 'completeness': 5, 'e...   \n",
              "3  {'argument_validity': 5, 'completeness': 4, 'e...   \n",
              "\n",
              "                   trajectory_judge__reasoning_trace  \n",
              "0  We need to evaluate the generated trajectory.\n",
              "...  \n",
              "1  We need to evaluate the trajectory.\n",
              "\n",
              "User requ...  \n",
              "2  We need to evaluate the trajectory.\n",
              "\n",
              "User requ...  \n",
              "3  We need to evaluate the trajectory.\n",
              "\n",
              "User requ...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from utils.convert_to_nemo_gym_format import (\n",
        "    build_nemo_gym_converter,\n",
        "    print_convert_to_nemo_gym_format_quickstart,\n",
        "    save_for_nemo_gym,\n",
        ")\n",
        "\n",
        "# Build converter only when you need NeMo Gym output.\n",
        "convert_to_nemo_gym_format = build_nemo_gym_converter(\n",
        "    tools=TOOLS,\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        "    environment_name=\"workplace_assistant\",\n",
        ")\n",
        "print_convert_to_nemo_gym_format_quickstart()\n",
        "\n",
        "output_path = \"workplace_assistant_train-gpt-oss.jsonl\"\n",
        "save_for_nemo_gym(filtered_df, output_path, convert_fn=convert_to_nemo_gym_format)\n",
        "\n",
        "print(\"\\nSample generated data (passed both quality stages):\")\n",
        "filtered_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated how to build a complete synthetic data generation pipeline for multi-step tool-calling tasks using **Data Designer**. The pipeline generates user queries, simulates agent trajectories, and applies dual-level LLM judge filtering to produce high-quality training data.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- **Scale up generation**: Increase `num_seeds` and `num_records` to produce larger training sets (1,000+ examples)\n",
        "- **Customize for your domain**: Replace the Workplace Assistant tools with your own tool definitions\n",
        "- **Add more multi-step patterns**: Define new patterns in `environment.json` to increase task diversity\n",
        "- **Tune judge thresholds**: Inspect rejected examples with `show_rejection_reasons()` and adjust filtering thresholds\n",
        "- **Train with NeMo Gym**: Use the exported JSONL file for GRPO training:\n",
        "\n",
        "```bash\n",
        "# Prepare data for NeMo Gym\n",
        "ng_prepare_data \"+config_paths=[workplace_assistant.yaml]\" \\\n",
        "    +output_dirpath=data/workplace_assistant \\\n",
        "    +input_jsonl=workplace_assistant_train-gpt-oss.jsonl\n",
        "\n",
        "# Run GRPO training\n",
        "python run_grpo_nemo_gym.py \\\n",
        "    --config=grpo_workplace_assistant.yaml \\\n",
        "    ++data.train_jsonl_fpath=data/workplace_assistant/train.jsonl\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
