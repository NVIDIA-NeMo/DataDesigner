# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

from __future__ import annotations

from pathlib import Path
from typing import Any

import pandas as pd

from data_designer.config.analysis.dataset_profiler import DatasetProfilerResults
from data_designer.config.config_builder import DataDesignerConfigBuilder
from data_designer.config.utils.visualization import WithRecordSamplerMixin
from data_designer.engine.dataset_builders.artifact_storage import ArtifactStorage
from data_designer.engine.dataset_builders.errors import ArtifactStorageError
from data_designer.interface.huggingface import HuggingFaceHubMixin


class DatasetCreationResults(WithRecordSamplerMixin, HuggingFaceHubMixin):
    """Results container for a Data Designer dataset creation run.

    This class provides access to the generated dataset, profiling analysis, and
    visualization utilities. It is returned by the DataDesigner.create() method
    and implements ResultsProtocol of the DataDesigner interface.
    """

    def __init__(
        self,
        *,
        artifact_storage: ArtifactStorage,
        analysis: DatasetProfilerResults,
        config_builder: DataDesignerConfigBuilder,
    ):
        """Creates a new instance with results based on a dataset creation run.

        Args:
            artifact_storage: Storage manager for accessing generated artifacts.
            analysis: Profiling results for the generated dataset.
            config_builder: Configuration builder used to create the dataset.
        """
        self.artifact_storage = artifact_storage
        self._analysis = analysis
        self._config_builder = config_builder

    def load_analysis(self) -> DatasetProfilerResults:
        """Load the profiling analysis results for the generated dataset.

        Returns:
            DatasetProfilerResults containing statistical analysis and quality metrics
                for each column in the generated dataset.
        """
        return self._analysis

    def load_dataset(self) -> pd.DataFrame:
        """Load the generated dataset as a pandas DataFrame.

        Returns:
            A pandas DataFrame containing the full generated dataset.
        """
        return self.artifact_storage.load_dataset()

    def load_processor_dataset(self, processor_name: str) -> pd.DataFrame:
        """Load the dataset generated by a processor.

        This only works for processors that write their artifacts in Parquet format.

        Args:
            processor_name: The name of the processor to load the dataset from.

        Returns:
            A pandas DataFrame containing the dataset generated by the processor.
        """
        try:
            dataset = self.artifact_storage.read_parquet_files(
                self.artifact_storage.processors_outputs_path / processor_name
            )
        except Exception as e:
            raise ArtifactStorageError(f"Failed to load dataset for processor {processor_name}: {e}")

        return dataset

    def get_path_to_processor_artifacts(self, processor_name: str) -> Path:
        """Get the path to the artifacts generated by a processor.

        Args:
            processor_name: The name of the processor to load the artifact from.

        Returns:
            The path to the artifacts.
        """
        if not self.artifact_storage.processors_outputs_path.exists():
            raise ArtifactStorageError(f"Processor {processor_name} has no artifacts.")
        return self.artifact_storage.processors_outputs_path / processor_name

    @classmethod
    def pull_from_hub(
        cls,
        repo_id: str,
        *,
        token: str | None = None,
        artifact_path: Path | str | None = None,
        split: str | None = None,
        **kwargs: Any,
    ) -> DatasetCreationResults:
        """Load a dataset and all artifacts from Hugging Face Hub as a DatasetCreationResults object.

        This classmethod downloads all artifacts from the Hugging Face Hub and reconstructs
        a DatasetCreationResults object that can be used just like one created from a local
        dataset generation run.

        Args:
            repo_id: The ID of the Hugging Face Hub repository (e.g., "username/dataset-name").
            token: Hugging Face token for authentication. If None, will check environment
                variables HF_TOKEN or HUGGINGFACE_HUB_TOKEN.
            artifact_path: Optional path to save downloaded artifacts. If None, a temporary
                directory will be used (note: temporary directories are cleaned up when
                the object is garbage collected).
            split: The split to load from the dataset. If None, the default split will be used.
            **kwargs: Additional arguments to pass to `pull_from_hub()` function.

        Returns:
            A DatasetCreationResults object containing the dataset, analysis, and all artifacts.

        Example:
            ```python
            from data_designer.interface.results import DatasetCreationResults

            # Load from hub (uses temporary directory)
            results = DatasetCreationResults.pull_from_hub("username/dataset-name")

            # Load to a specific directory
            results = DatasetCreationResults.pull_from_hub(
                "username/dataset-name",
                artifact_path="./downloaded_datasets/my_dataset"
            )

            # Access the dataset and analysis
            df = results.load_dataset()
            analysis = results.load_analysis()
            ```
        """
        # Delegate to the mixin method using super() to avoid recursion
        return super(DatasetCreationResults, cls).pull_from_hub(
            repo_id, token=token, artifact_path=artifact_path, split=split, **kwargs
        )
