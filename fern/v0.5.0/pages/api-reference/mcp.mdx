---
title: MCP (Model Context Protocol)
description: Configuration and execution classes for tool use via MCP.
---

The `mcp` module defines configuration and execution classes for tool use via MCP (Model Context Protocol).

## Configuration Classes

- **[MCPProvider](#mcpprovider)**: Configure remote MCP servers via SSE transport
- **[LocalStdioMCPProvider](#localstdiomcpprovider)**: Configure local MCP servers as subprocesses via stdio transport
- **[ToolConfig](#toolconfig)**: Define which tools are available for LLM columns and how they are constrained

For user-facing guides, see:

- **[MCP Providers](/docs/concepts/mcp/mcp-providers)** - Configure local or remote MCP providers
- **[Tool Configs](/docs/concepts/mcp/tool-configs)** - Define tool permissions and limits
- **[Enabling Tools](/docs/concepts/mcp/enabling-tools)** - Use tools in LLM columns
- **[Traces](/docs/concepts/traces)** - Capture full conversation history

## MCPProvider

Remote MCP provider configuration using SSE (Server-Sent Events) transport.

```python
import data_designer.config as dd

provider = dd.MCPProvider(
    name="remote-mcp",
    endpoint="http://localhost:8080/sse",
    api_key="MCP_API_KEY",
)
```

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `name` | `str` | Yes | Unique identifier for the provider |
| `endpoint` | `str` | Yes | SSE endpoint URL |
| `api_key` | `str` | No | API key or environment variable name |
| `provider_type` | `str` | No | Always `"sse"` (set automatically) |

## LocalStdioMCPProvider

Local MCP provider configuration using stdio transport (subprocess).

```python
import data_designer.config as dd

provider = dd.LocalStdioMCPProvider(
    name="local-mcp",
    command="python",
    args=["-m", "my_mcp_server"],
    env={"DEBUG": "true"},
)
```

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `name` | `str` | Yes | Unique identifier for the provider |
| `command` | `str` | Yes | Executable to run |
| `args` | `list[str]` | No | Command-line arguments |
| `env` | `dict[str, str]` | No | Environment variables for the subprocess |
| `provider_type` | `str` | No | Always `"stdio"` (set automatically) |

## ToolConfig

Tool configuration defining tool access and constraints for LLM columns.

```python
import data_designer.config as dd

tool_config = dd.ToolConfig(
    tool_alias="my-tools",
    providers=["local-mcp"],
    allow_tools=["search", "get_fact"],
    max_tool_call_turns=5,
    timeout_sec=30.0,
)
```

| Field | Type | Required | Default | Description |
|-------|------|----------|---------|-------------|
| `tool_alias` | `str` | Yes | - | Unique identifier referenced by columns |
| `providers` | `list[str]` | Yes | - | MCP provider names to use |
| `allow_tools` | `list[str]` | No | `None` | Restrict to specific tools (`None` = all) |
| `max_tool_call_turns` | `int` | No | `5` | Maximum tool-calling iterations |
| `timeout_sec` | `float` | No | `60.0` | Per-call timeout in seconds |

## Internal Architecture

### Parallel Structure

| Model Layer | MCP Layer | Purpose |
|-------------|-----------|---------|
| `ModelProviderRegistry` | `MCPProviderRegistry` | Holds provider configurations |
| `ModelRegistry` | `MCPRegistry` | Manages configs by alias, lazy facade creation |
| `ModelFacade` | `MCPFacade` | Lightweight facade scoped to specific config |
| `ModelConfig.alias` | `ToolConfig.tool_alias` | Alias for referencing in column configs |

### MCPProviderRegistry

Holds MCP provider configurations. Can be empty (MCP is optional). Created first during resource initialization.

### MCPRegistry

The central registry for tool configurations:

- Holds `ToolConfig` instances by `tool_alias`
- Lazily creates `MCPFacade` instances via `get_mcp(tool_alias)`
- Manages shared connection pool and tool cache across all facades
- Validates that tool configs reference valid providers

### MCPFacade

A lightweight facade scoped to a specific `ToolConfig`. Key methods:

| Method | Description |
|--------|-------------|
| `tool_call_count(response)` | Count tool calls in a completion response |
| `has_tool_calls(response)` | Check if response contains tool calls |
| `get_tool_schemas()` | Get OpenAI-format tool schemas for this config |
| `process_completion_response(response)` | Execute tool calls and return messages |
| `refuse_completion_response(response)` | Refuse tool calls gracefully (budget exhaustion) |

Properties: `tool_alias`, `providers`, `max_tool_call_turns`, `allow_tools`, `timeout_sec`

### I/O Layer

The `io.py` module provides low-level MCP communication with performance optimizations:

**Single event loop architecture:**
All MCP operations funnel through a dedicated background daemon thread running an asyncio event loop. This allows:

- Efficient concurrent I/O without per-thread event loop overhead
- Natural session sharing across all worker threads
- Clean async implementation for parallel tool calls

**Session pooling:**
MCP sessions are created lazily and kept alive for the program's duration:

- One session per provider (keyed by serialized config)
- No per-call connection/handshake overhead
- Graceful cleanup on program exit via `atexit` handler

**Request coalescing:**
The `list_tools` operation uses request coalescing to prevent thundering herd:

- When multiple workers request tools from the same provider simultaneously
- Only one request is made; others wait for the cached result
- Uses asyncio.Lock per provider key

**Parallel tool execution:**
The `call_tools_parallel()` function executes multiple tool calls concurrently via `asyncio.gather()`. This is used by MCPFacade when the model returns parallel tool calls in a single response.

### Integration with ModelFacade.generate()

The `ModelFacade.generate()` method accepts an optional `tool_alias` parameter:

```python
output, messages = model_facade.generate(
    prompt="Search and answer...",
    parser=my_parser,
    tool_alias="my-tools",  # Enables tool calling for this generation
)
```

When `tool_alias` is provided:

1. `ModelFacade` looks up the `MCPFacade` from `MCPRegistry`
2. Tool schemas are fetched and passed to the LLM
3. After each completion, `MCPFacade` processes tool calls
4. Turn counting tracks iterations; refusal kicks in when budget exhausted
5. Messages (including tool results) are returned for trace capture
